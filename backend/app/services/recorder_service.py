import asyncio
import json
import logging
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

# å¯¼å…¥ç°æœ‰ä¸šåŠ¡é€»è¾‘æ¨¡å— (é›¶ä¿®æ”¹å¤ç”¨)
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from core.network_recorder import NetworkRecorder
from core.browser_manager import BrowserManager  
from core.resource_archiver import ResourceArchiver
from models.request_record import RequestRecord
import utils.file_helper as file_helper

from ..config import settings
from ..database import HybridStorage
from ..websocket import manager
from .cache_service import get_cache_service

logger = logging.getLogger(__name__)

class RecorderService:
    """
    ç½‘ç»œå½•åˆ¶æœåŠ¡ - å°è£…ç°æœ‰NetworkRecorderç­‰ä¸šåŠ¡é€»è¾‘
    æä¾›FastAPIå…¼å®¹çš„å¼‚æ­¥æ¥å£ï¼ŒåŒæ—¶ä¿æŒ100%åŠŸèƒ½ä¸€è‡´æ€§
    ä½¿ç”¨å•ä¾‹æ¨¡å¼ç¡®ä¿ä¼šè¯çŠ¶æ€åœ¨æ‰€æœ‰APIè°ƒç”¨é—´å…±äº«
    """
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(RecorderService, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        # é˜²æ­¢é‡å¤åˆå§‹åŒ–
        if RecorderService._initialized:
            return
            
        self.cache_service = get_cache_service()
        self.active_sessions: Dict[str, Dict] = {}
        self.session_recorders: Dict[str, NetworkRecorder] = {}
        self.browser_managers: Dict[str, BrowserManager] = {}
        self.session_archivers: Dict[str, ResourceArchiver] = {}

        self._realtime_tasks: Dict[str, asyncio.Task] = {}
        self._realtime_sent_counts: Dict[str, int] = {}
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(settings.data_dir, exist_ok=True)
        
        RecorderService._initialized = True
        logger.info("RecorderServiceå•ä¾‹å®ä¾‹å·²åˆ›å»º")

    def _serialize_request_for_api(self, request: Any, session_id: str) -> Dict:
        if isinstance(request, dict):
            request_dict = request.copy()
            request_dict["session_id"] = session_id
            return request_dict

        if hasattr(request, 'to_dict'):
            request_dict = request.to_dict()
            request_dict["session_id"] = session_id
            return request_dict

        if hasattr(request, '__dict__'):
            request_dict = {
                key: value for key, value in request.__dict__.items()
                if not key.startswith('_') and isinstance(value, (str, int, float, bool, list, dict, type(None)))
            }
            request_dict["session_id"] = session_id
            return request_dict

        return {"session_id": session_id, "raw": str(request)}

    def _filter_requests(
        self,
        requests: List[Dict],
        q: Optional[str] = None,
        resource_type: Optional[str] = None,
        method: Optional[str] = None,
        status: Optional[int] = None,
    ) -> List[Dict]:
        filtered = requests

        if q:
            q_lower = q.lower()
            filtered = [r for r in filtered if q_lower in str(r.get("url", "")).lower()]

        if resource_type:
            filtered = [r for r in filtered if r.get("resource_type") == resource_type]

        if method:
            filtered = [r for r in filtered if str(r.get("method", "")).upper() == method.upper()]

        if status is not None:
            filtered = [r for r in filtered if (r.get("status") if r.get("status") is not None else r.get("status_code")) == status]

        return filtered

    def _ensure_realtime_task(self, session_id: str) -> None:
        existing = self._realtime_tasks.get(session_id)
        if existing and not existing.done():
            return
        self._realtime_sent_counts[session_id] = 0
        self._realtime_tasks[session_id] = asyncio.create_task(self._push_realtime_updates(session_id))
        logger.info(f"å¯åŠ¨å®æ—¶æ¨é€ä»»åŠ¡: {session_id}")

    async def _cancel_realtime_task(self, session_id: str) -> None:
        task = self._realtime_tasks.pop(session_id, None)
        self._realtime_sent_counts.pop(session_id, None)
        if task and not task.done():
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
            logger.info(f"å·²å–æ¶ˆå®æ—¶æ¨é€ä»»åŠ¡: {session_id}")

    async def _push_realtime_updates(self, session_id: str) -> None:
        while True:
            session = self.active_sessions.get(session_id)
            recorder = self.session_recorders.get(session_id)
            browser_manager = self.browser_managers.get(session_id)

            if not session or not recorder:
                logger.info(f"å®æ—¶æ¨é€é€€å‡º(ä¼šè¯æˆ–å½•åˆ¶å™¨ä¸å­˜åœ¨): {session_id}")
                return
            if session.get("status") not in {"starting", "running"}:
                logger.info(f"å®æ—¶æ¨é€é€€å‡º(çŠ¶æ€ä¸º{session.get('status')}): {session_id}")
                return

            try:
                if browser_manager and getattr(browser_manager, "page", None) is not None:
                    try:
                        session["current_url"] = browser_manager.page.url
                    except Exception:
                        pass

                records = recorder.records
                sent_count = self._realtime_sent_counts.get(session_id, 0)
                new_records = records[sent_count:]
                self._realtime_sent_counts[session_id] = len(records)

                recent_requests = [
                    self._serialize_request_for_api(r, session_id)
                    for r in new_records[-20:]
                ]

                total_requests = len(records)
                completed_requests = len([r for r in records if getattr(r, "status", None) is not None])

                progress_data = {
                    "session_id": session_id,
                    "status": session.get("status"),
                    "current_url": session.get("current_url"),
                    "total_requests": total_requests,
                    "completed_requests": completed_requests,
                    "recent_requests": recent_requests,
                    "timestamp": datetime.now().isoformat(),
                }

                await manager.send_crawler_progress(progress_data)

            except asyncio.CancelledError:
                return
            except Exception as e:
                logger.warning(f"å®æ—¶æ¨é€å¤±è´¥ {session_id}: {e}")
                return

            await asyncio.sleep(1)
    
    async def create_session(self, url: str, session_name: Optional[str] = None, config: Dict = None) -> str:
        """åˆ›å»ºæ–°çš„çˆ¬è™«ä¼šè¯"""
        # ä½¿ç”¨æ—¶é—´æˆ³æ ¼å¼ä½œä¸ºsession_idï¼Œç¡®ä¿ä¸ç›®å½•å‘½åä¸€è‡´
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        session_id = f"session_{timestamp}"
        
        session_data = {
            "session_id": session_id,
            "session_name": session_name or session_id,
            "url": url,
            "config": config or {},
            "status": "created",
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "total_requests": 0,
            "completed_requests": 0,
            "errors": [],
            "progress": {}
        }
        
        self.active_sessions[session_id] = session_data
        
        # åˆå§‹åŒ–BrowserManager (ç›´æ¥ä½¿ç”¨ç°æœ‰ç±»)
        browser_manager = BrowserManager()
        self.browser_managers[session_id] = browser_manager
        
        # åˆ›å»ºä¼šè¯èµ„æºå­˜å‚¨ç›®å½•å¹¶åˆå§‹åŒ–ResourceArchiver
        sessions_base_dir = Path(settings.data_dir) / "sessions"
        archiver = ResourceArchiver(
            base_output_dir=sessions_base_dir,
            log_callback=lambda msg: logger.info(f"[ResourceArchiver] {msg}"),
            session_id=session_id,
        )
        archiver.set_start_url(url)
        self.session_archivers[session_id] = archiver
        
        # Create fresh instances for each session with proper config
        config = session_data["config"]
        recorder = NetworkRecorder(
            browser_manager=browser_manager,
            log_callback=lambda msg: print(f" [å½•åˆ¶] {msg}"),
            archiver=archiver,
            config=config  # ä¼ é€’ç”¨æˆ·é…ç½®
        )
        
        # å­˜å‚¨å½•åˆ¶å™¨åˆ°å­—å…¸ä¸­
        self.session_recorders[session_id] = recorder
        
        logger.info(f"åˆ›å»ºä¼šè¯ {session_id}: {url} (æˆªå›¾åŠŸèƒ½: {'å¯ç”¨' if config.get('capture_screenshots', False) else 'ç¦ç”¨'})")
        return session_id
    
    async def start_recording(self, session_id: str):
        """å¯åŠ¨ç½‘ç»œå½•åˆ¶"""
        if session_id not in self.active_sessions:
            raise ValueError(f"ä¼šè¯ {session_id} ä¸å­˜åœ¨")
        
        session = self.active_sessions[session_id]
        recorder = self.session_recorders[session_id]
        browser_manager = self.browser_managers[session_id]
        archiver = self.session_archivers.get(session_id)
        
        try:
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            session["status"] = "starting"
            session["updated_at"] = datetime.now().isoformat()

            # ç¡®ä¿ä¼šè¯åœ¨å†…å­˜ä¸­å¯è§ï¼Œå¹¶å°½æ—©å¯åŠ¨å®æ—¶æ¨é€ï¼ˆä¸è¦ç­‰å¾… page.goto å®Œæˆï¼‰
            self.active_sessions[session_id] = session
            self._ensure_realtime_task(session_id)
            
            # ğŸŸ¢ ä½¿ç”¨ç°æœ‰BrowserManagerå¯åŠ¨æµè§ˆå™¨ - ç›´æ¥è°ƒç”¨asyncæ–¹æ³•
            config = session["config"]
            browser_context = await browser_manager.create_browser_context(
                config.get("headless", True),
                config.get("user_agent"),
                config.get("timeout", 30)
            )

            # ç¡®ä¿å½•åˆ¶å™¨å·²ç»ç»‘å®š archiverï¼ˆç”¨äºå“åº”è½ç›˜ã€hookè½ç›˜ã€æµè§ˆå™¨æ•°æ®è½ç›˜ï¼‰
            if archiver is not None:
                recorder.set_archiver(archiver)
                try:
                    if hasattr(browser_manager, "set_screenshot_directory"):
                        browser_manager.set_screenshot_directory(str(archiver.session_dir / "screenshots"))
                except Exception:
                    pass
            
            # ğŸŸ¢ ä½¿ç”¨ç°æœ‰NetworkRecorderå¼€å§‹å½•åˆ¶ - ç›´æ¥è°ƒç”¨asyncæ–¹æ³•
            await recorder.start_recording(browser_context, session["url"])
            
            # è®¾ç½®å½“å‰URLç”¨äºå®æ—¶é¢„è§ˆ
            session["current_url"] = session["url"]
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€å¹¶ç¡®ä¿å­˜å‚¨
            session["status"] = "running"
            session["updated_at"] = datetime.now().isoformat()
            
            # ç¡®ä¿ä¼šè¯åœ¨å†…å­˜ä¸­æ­£ç¡®å­˜å‚¨
            self.active_sessions[session_id] = session

            self._ensure_realtime_task(session_id)
            
            logger.info(f"ä¼šè¯ {session_id} å¼€å§‹å½•åˆ¶ï¼Œå½“å‰æ´»åŠ¨ä¼šè¯æ•°: {len(self.active_sessions)}")
            logger.info(f"æ´»åŠ¨ä¼šè¯åˆ—è¡¨: {list(self.active_sessions.keys())}")
            
        except Exception as e:
            session["status"] = "failed"
            session["errors"].append(str(e))
            logger.error(f"å¯åŠ¨å½•åˆ¶å¤±è´¥ {session_id}: {e}")
            raise
    
    async def stop_recording(self, session_id: str):
        """åœæ­¢ç½‘ç»œå½•åˆ¶"""
        if session_id not in self.active_sessions:
            raise ValueError(f"ä¼šè¯ {session_id} ä¸å­˜åœ¨")
        
        session = self.active_sessions[session_id]
        recorder = self.session_recorders.get(session_id)
        browser_manager = self.browser_managers.get(session_id)
        archiver = self.session_archivers.get(session_id)
        
        try:
            # ğŸŸ¢ ä½¿ç”¨ç°æœ‰NetworkRecorderåœæ­¢å½•åˆ¶ - ç›´æ¥è°ƒç”¨asyncæ–¹æ³•
            if recorder:
                await recorder.stop()

            # å½•åˆ¶åœæ­¢åï¼Œå°½å¯èƒ½æŠ“å–å¹¶ä¿å­˜ JS èµ„æºï¼ˆå³ä½¿éƒ¨åˆ†è„šæœ¬ä»ç¼“å­˜å¯¼è‡´ response.body ä¸ºç©ºä¹Ÿèƒ½è¡¥å…¨ï¼‰
            if archiver is not None and browser_manager and getattr(browser_manager, "page", None) is not None:
                try:
                    await archiver.save_js_resources(browser_manager.page)
                    archiver.beautify_js_files(use_builtin=True)
                except Exception as e:
                    logger.warning(f"ä¿å­˜JSèµ„æºå¤±è´¥ {session_id}: {e}")
                page = getattr(browser_manager, "page", None)
                if page is not None:
                    try:
                        storage_snapshot = await page.evaluate(
                            """() => {
                                const ls = {};
                                const ss = {};
                                try {
                                    for (let i = 0; i < localStorage.length; i++) {
                                        const k = localStorage.key(i);
                                        ls[k] = localStorage.getItem(k);
                                    }
                                } catch (e) {}
                                try {
                                    for (let i = 0; i < sessionStorage.length; i++) {
                                        const k = sessionStorage.key(i);
                                        ss[k] = sessionStorage.getItem(k);
                                    }
                                } catch (e) {}
                                return { url: location.href, localStorage: ls, sessionStorage: ss };
                            }"""
                        )
                        archiver.save_browser_data("STORAGE_SNAPSHOT", storage_snapshot)
                    except Exception as e:
                        logger.warning(f"å¯¼å‡ºstorageå¿«ç…§å¤±è´¥ {session_id}: {e}")

                    try:
                        perf_snapshot = await page.evaluate(
                            """() => {
                                try {
                                    const nav = performance.getEntriesByType('navigation') || [];
                                    const res = performance.getEntriesByType('resource') || [];
                                    return {
                                        url: location.href,
                                        navigation: nav.map(n => ({
                                            name: n.name,
                                            startTime: n.startTime,
                                            duration: n.duration,
                                            domContentLoadedEventEnd: n.domContentLoadedEventEnd,
                                            loadEventEnd: n.loadEventEnd,
                                            responseEnd: n.responseEnd,
                                            domComplete: n.domComplete
                                        })),
                                        resources: res.map(r => ({
                                            name: r.name,
                                            initiatorType: r.initiatorType,
                                            startTime: r.startTime,
                                            duration: r.duration,
                                            transferSize: r.transferSize,
                                            encodedBodySize: r.encodedBodySize,
                                            decodedBodySize: r.decodedBodySize
                                        }))
                                    };
                                } catch (e) {
                                    return { error: String(e) };
                                }
                            }"""
                        )
                        archiver.save_browser_data("PERFORMANCE_SNAPSHOT", perf_snapshot)
                    except Exception as e:
                        logger.warning(f"å¯¼å‡ºperformanceå¿«ç…§å¤±è´¥ {session_id}: {e}")

                    try:
                        dom_snapshot = await page.evaluate(
                            """() => {
                                try {
                                    const html = document.documentElement ? document.documentElement.outerHTML : '';
                                    return { url: location.href, title: document.title, html: html, length: html.length };
                                } catch (e) {
                                    return { error: String(e) };
                                }
                            }"""
                        )
                        if isinstance(dom_snapshot, dict) and isinstance(dom_snapshot.get("html"), str):
                            if len(dom_snapshot["html"]) > 1000000:
                                dom_snapshot["html"] = dom_snapshot["html"][:1000000]
                                dom_snapshot["truncated"] = True
                        archiver.save_browser_data("DOM_FINAL", dom_snapshot)
                    except Exception as e:
                        logger.warning(f"å¯¼å‡ºDOMå¿«ç…§å¤±è´¥ {session_id}: {e}")

                try:
                    storage_state_path = archiver.session_dir / "browser_data" / "storage" / "storage_state.json"
                    await browser_manager.export_storage_state(storage_state_path)
                    try:
                        legacy_path = archiver.session_dir / "browser_data" / "storage_state.json"
                        legacy_path.write_text(storage_state_path.read_text(encoding="utf-8"), encoding="utf-8")
                    except Exception:
                        pass
                except Exception as e:
                    logger.warning(f"å¯¼å‡ºstorage_stateå¤±è´¥ {session_id}: {e}")

            # ç”Ÿæˆ metadata / har / requests.jsonï¼ˆåŸºäº RequestRecordï¼ŒåŒ…å« response_body_path ç­‰ï¼‰
            if archiver is not None and recorder:
                try:
                    archiver.save_requests(recorder.records)
                    archiver.save_metadata(recorder.records)
                    archiver.save_har(recorder.records)
                except Exception as e:
                    logger.warning(f"å¯¼å‡ºä¼šè¯æ–‡ä»¶å¤±è´¥ {session_id}: {e}")

            # ç”Ÿæˆå¯æ‰§è¡Œ Python å›æ”¾ä»£ç 
            if archiver is not None:
                try:
                    from core.code_generator import generate_code_from_session, generate_per_request_scripts

                    replay_code = generate_code_from_session(archiver.session_dir)
                    replay_path = archiver.session_dir / "replay_session.py"
                    with open(replay_path, "w", encoding="utf-8") as f:
                        f.write(replay_code)
                    logger.info(f"å·²ç”Ÿæˆå›æ”¾ä»£ç : {replay_path}")
                    try:
                        generate_per_request_scripts(archiver.session_dir)
                    except Exception as e:
                        logger.warning(f"ç”Ÿæˆé€è¯·æ±‚è„šæœ¬å¤±è´¥ {session_id}: {e}")
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆå›æ”¾ä»£ç å¤±è´¥ {session_id}: {e}")
            
            # ğŸŸ¢ ä½¿ç”¨ç°æœ‰BrowserManagerå…³é—­æµè§ˆå™¨ - ç›´æ¥è°ƒç”¨asyncæ–¹æ³•
            if browser_manager:
                await browser_manager.close()

            session["status"] = "completed"
            session["updated_at"] = datetime.now().isoformat()
            self.active_sessions[session_id] = session

            await self._cancel_realtime_task(session_id)

            # ä¿å­˜å½•åˆ¶ç»“æœåˆ°JSONæ–‡ä»¶ (ä¿æŒç°æœ‰æ ¼å¼)
            await self._save_session_data(session_id)
            
            logger.info(f"ä¼šè¯ {session_id} åœæ­¢å½•åˆ¶ï¼Œå½“å‰æ´»åŠ¨ä¼šè¯æ•°: {len(self.active_sessions)}")
            logger.info(f"æ´»åŠ¨ä¼šè¯åˆ—è¡¨: {list(self.active_sessions.keys())}")
            
        except Exception as e:
            session["status"] = "failed"
            session["errors"].append(str(e))
            logger.error(f"åœæ­¢å½•åˆ¶å¤±è´¥ {session_id}: {e}")
            raise
    
    async def get_session_status(self, session_id: str) -> Dict:
        """è·å–ä¼šè¯çŠ¶æ€"""
        if session_id not in self.active_sessions:
            raise ValueError(f"ä¼šè¯ {session_id} ä¸å­˜åœ¨")
        
        session = self.active_sessions[session_id]
        recorder = self.session_recorders.get(session_id)
        
        # ğŸŸ¢ è·å–ç°æœ‰NetworkRecorderçš„å½•åˆ¶è¿›åº¦ - ä½¿ç”¨å¯ç”¨çš„å±æ€§
        if recorder:
            try:
                records = recorder.records
                total_requests = len(records)
                completed_requests = len([r for r in records if r.status is not None])
                
                progress = {
                    "total_requests": total_requests,
                    "completed_requests": completed_requests,
                    "is_recording": recorder.is_recording
                }
                session["progress"] = progress
                session["total_requests"] = total_requests
                session["completed_requests"] = completed_requests
                session["updated_at"] = datetime.now().isoformat()
                
                logger.info(f"ä¼šè¯ {session_id} è¿›åº¦æ›´æ–°: {completed_requests}/{total_requests}, å½•åˆ¶çŠ¶æ€: {recorder.is_recording}")
            except Exception as e:
                logger.warning(f"è·å–è¿›åº¦å¤±è´¥ {session_id}: {e}")
                # è®¾ç½®é»˜è®¤å€¼é¿å…0/0æ˜¾ç¤º
                session["total_requests"] = session.get("total_requests", 0) 
                session["completed_requests"] = session.get("completed_requests", 0)
        else:
            # æ²¡æœ‰recorderæ—¶ä½¿ç”¨å·²æœ‰æ•°æ®æˆ–é»˜è®¤å€¼
            session["total_requests"] = session.get("total_requests", 0)
            session["completed_requests"] = session.get("completed_requests", 0)
        
        return session.copy()
    
    async def list_sessions(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
        sessions_by_id: Dict[str, Dict] = {}

        for session_id, session_data in self.active_sessions.items():
            sessions_by_id[session_id] = session_data.copy()

        try:
            sessions_file = HybridStorage.get_sessions_json_path()
            HybridStorage.ensure_sessions_json_exists()
            historical_sessions = HybridStorage.load_json_data(sessions_file)
            if historical_sessions:
                for s in historical_sessions:
                    sid = s.get("session_id")
                    if sid and sid not in sessions_by_id:
                        sessions_by_id[sid] = s
        except Exception as e:
            logger.warning(f"åŠ è½½å†å²ä¼šè¯å¤±è´¥: {e}")

        sessions_list = list(sessions_by_id.values())

        try:
            from core.code_generator import generate_per_request_scripts

            sessions_base_dir = Path(settings.data_dir) / "sessions"
            for s in sessions_list:
                sid = (s.get("session_id") or s.get("session_name") or "").strip()
                if not sid:
                    continue

                safe_sid = Path(sid).name
                session_dir = sessions_base_dir / safe_sid
                if not session_dir.exists() or not session_dir.is_dir():
                    continue

                requests_file = session_dir / "requests.json"
                if not requests_file.exists():
                    continue

                out_py = session_dir / "requests_py"
                out_js = session_dir / "requests_js"
                try:
                    py_count = len(list(out_py.glob("*.py"))) if out_py.exists() else 0
                    js_count = len(list(out_js.glob("*.js"))) if out_js.exists() else 0
                except Exception:
                    py_count = 0
                    js_count = 0

                if py_count <= 1 and js_count <= 1:
                    try:
                        generate_per_request_scripts(session_dir)
                    except Exception as e:
                        logger.warning(f"è¡¥ç”Ÿæˆé€è¯·æ±‚è„šæœ¬å¤±è´¥ {safe_sid}: {e}")
        except Exception as e:
            logger.warning(f"é€è¯·æ±‚è„šæœ¬è‡ªæ„ˆæ£€æŸ¥å¤±è´¥: {e}")

        def _sort_key(s: Dict) -> tuple:
            created_raw = s.get("created_at") or s.get("updated_at") or ""
            sid = s.get("session_id") or s.get("session_name") or ""

            dt = None
            if isinstance(created_raw, str) and created_raw:
                try:
                    dt = datetime.fromisoformat(created_raw)
                except Exception:
                    dt = None

            if dt is None and isinstance(sid, str) and sid.startswith("session_"):
                try:
                    ts = sid[len("session_"):]
                    dt = datetime.strptime(ts, "%Y%m%d_%H%M%S")
                except Exception:
                    dt = None

            if dt is None:
                dt = datetime.min

            return (dt, str(sid))

        sessions_list.sort(key=_sort_key, reverse=True)
        return sessions_list
    
    async def get_session_requests(self, session_id: str, offset: int = 0, limit: int = 100) -> List[Dict]:
        """è·å–ä¼šè¯çš„è¯·æ±‚è®°å½•"""
        session = self.active_sessions.get(session_id)
        recorder = self.session_recorders.get(session_id)
        if session and recorder and session.get("status") in {"starting", "running"}:
            serialized_requests = []
            for request in recorder.records:
                if isinstance(request, dict):
                    request_dict = request.copy()
                    request_dict["session_id"] = session_id
                    serialized_requests.append(request_dict)
                elif hasattr(request, 'to_dict'):
                    request_dict = request.to_dict()
                    request_dict["session_id"] = session_id
                    serialized_requests.append(request_dict)
                elif hasattr(request, '__dict__'):
                    request_dict = {
                        key: value for key, value in request.__dict__.items()
                        if not key.startswith('_') and isinstance(value, (str, int, float, bool, list, dict, type(None)))
                    }
                    request_dict["session_id"] = session_id
                    serialized_requests.append(request_dict)

            return serialized_requests[offset:offset + limit]

        # ğŸŸ¢ ä¼˜å…ˆä»sessionçº§åˆ«å­˜å‚¨è¯»å–æ•°æ®
        session_requests = HybridStorage.load_session_requests(session_id)
        
        if session_requests:
            return session_requests[offset:offset + limit]
        
        # ğŸŸ¢ å‘åå…¼å®¹ï¼šå¦‚æœsessionçº§åˆ«æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»å…¨å±€requests.jsonè¯»å–
        requests_file = HybridStorage.get_requests_json_path()
        
        if not os.path.exists(requests_file):
            return []

        try:
            with open(requests_file, 'r', encoding='utf-8') as f:
                all_requests = json.load(f)

            session_requests = [
                req for req in all_requests
                if req.get("session_id") == session_id
            ]

            return session_requests[offset:offset + limit]

        except Exception as e:
            logger.error(f"è¯»å–è¯·æ±‚æ•°æ®å¤±è´¥: {e}")
            return []

    async def get_session_requests_page(
        self,
        session_id: str,
        offset: int = 0,
        limit: int = 100,
        q: Optional[str] = None,
        resource_type: Optional[str] = None,
        method: Optional[str] = None,
        status: Optional[int] = None,
    ) -> Dict:
        """è·å–ä¼šè¯è¯·æ±‚åˆ†é¡µæ•°æ®ï¼ˆåŒ…å« totalï¼‰"""
        session = self.active_sessions.get(session_id)
        recorder = self.session_recorders.get(session_id)

        if session and recorder and session.get("status") in {"starting", "running"}:
            all_requests = [self._serialize_request_for_api(r, session_id) for r in recorder.records]
            filtered = self._filter_requests(all_requests, q=q, resource_type=resource_type, method=method, status=status)
            total = len(filtered)
            return {
                "session_id": session_id,
                "requests": filtered[offset:offset + limit],
                "total": total,
                "offset": offset,
                "limit": limit,
            }

        # ğŸŸ¢ ä¼˜å…ˆä»sessionçº§åˆ«å­˜å‚¨è¯»å–æ•°æ®
        session_requests = HybridStorage.load_session_requests(session_id)
        
        if not session_requests:
            # ğŸŸ¢ å‘åå…¼å®¹ï¼šå¦‚æœsessionçº§åˆ«æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»å…¨å±€requests.jsonè¯»å–
            requests_file = HybridStorage.get_requests_json_path()
            if os.path.exists(requests_file):
                try:
                    with open(requests_file, 'r', encoding='utf-8') as f:
                        all_requests = json.load(f)
                    session_requests = [
                        req for req in all_requests
                        if req.get("session_id") == session_id
                    ]
                except Exception as e:
                    logger.error(f"è¯»å–å…¨å±€requests.jsonå¤±è´¥: {e}")
                    session_requests = []
        
        if not session_requests:
            return {
                "session_id": session_id,
                "requests": [],
                "total": 0,
                "offset": offset,
                "limit": limit,
            }

        filtered = self._filter_requests(session_requests, q=q, resource_type=resource_type, method=method, status=status)
        total = len(filtered)
        return {
            "session_id": session_id,
            "requests": filtered[offset:offset + limit],
            "total": total,
            "offset": offset,
            "limit": limit,
        }

    async def get_all_session_requests(self, session_id: str) -> List[Dict]:
        """è·å–ä¼šè¯å…¨éƒ¨è¯·æ±‚ï¼ˆç”¨äºç´¢å¼•/åˆ†æç­‰åœºæ™¯ï¼‰"""
        session = self.active_sessions.get(session_id)
        recorder = self.session_recorders.get(session_id)

        if session and recorder and session.get("status") in {"starting", "running"}:
            return [self._serialize_request_for_api(r, session_id) for r in recorder.records]

        # ğŸŸ¢ ä¼˜å…ˆä»sessionçº§åˆ«å­˜å‚¨è¯»å–æ•°æ®
        session_requests = HybridStorage.load_session_requests(session_id)
        
        if session_requests:
            return session_requests
        
        # ğŸŸ¢ å‘åå…¼å®¹ï¼šå¦‚æœsessionçº§åˆ«æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»å…¨å±€requests.jsonè¯»å–
        requests_file = HybridStorage.get_requests_json_path()
        if not os.path.exists(requests_file):
            return []

        try:
            with open(requests_file, 'r', encoding='utf-8') as f:
                all_requests = json.load(f)

            return [
                req for req in all_requests
                if req.get("session_id") == session_id
            ]

        except Exception as e:
            logger.error(f"è¯»å–å…¨éƒ¨è¯·æ±‚æ•°æ®å¤±è´¥: {e}")
            return []
    
    async def delete_session(self, session_id: str):
        """åˆ é™¤ä¼šè¯"""
        try:
            logger.info(f"å¼€å§‹åˆ é™¤ä¼šè¯: {session_id}")
            
            # å…ˆåœæ­¢å½•åˆ¶ï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
            if session_id in self.active_sessions:
                session = self.active_sessions[session_id]
                if session.get("status") == "running":
                    try:
                        await self.stop_recording(session_id)
                        logger.info(f"å·²åœæ­¢è¿è¡Œä¸­çš„ä¼šè¯: {session_id}")
                    except Exception as e:
                        logger.warning(f"åœæ­¢ä¼šè¯æ—¶å‡ºé”™: {e}")
            
            # æ¸…ç†å†…å­˜ä¸­çš„ä¼šè¯æ•°æ®
            self.active_sessions.pop(session_id, None)
            self.session_recorders.pop(session_id, None)  
            self.browser_managers.pop(session_id, None)
            await self._cancel_realtime_task(session_id)
            logger.info(f"å·²æ¸…ç†å†…å­˜ä¸­çš„ä¼šè¯æ•°æ®: {session_id}")
            
            # åˆ é™¤æŒä¹…åŒ–å­˜å‚¨ä¸­çš„ä¼šè¯æ•°æ®
            try:
                # åˆ é™¤sessions.jsonä¸­çš„ä¼šè¯è®°å½•
                sessions_file = HybridStorage.get_sessions_json_path()
                sessions = HybridStorage.load_json_data(sessions_file)
                if sessions:
                    # è¿‡æ»¤æ‰è¦åˆ é™¤çš„ä¼šè¯
                    sessions = [s for s in sessions if s.get("session_id") != session_id]
                    HybridStorage.save_json_data(sessions_file, sessions)
                    logger.info(f"å·²ä»sessions.jsonåˆ é™¤ä¼šè¯: {session_id}")
                
                # åˆ é™¤requests.jsonä¸­çš„ç›¸å…³è¯·æ±‚è®°å½•  
                requests_file = HybridStorage.get_requests_json_path()
                requests = HybridStorage.load_json_data(requests_file)
                if requests:
                    # è¿‡æ»¤æ‰è¯¥ä¼šè¯çš„æ‰€æœ‰è¯·æ±‚
                    original_count = len(requests)
                    requests = [r for r in requests if r.get("session_id") != session_id]
                    deleted_count = original_count - len(requests)
                    HybridStorage.save_json_data(requests_file, requests)
                    logger.info(f"å·²ä»requests.jsonåˆ é™¤ {deleted_count} ä¸ªè¯·æ±‚è®°å½•")
                
            except Exception as e:
                logger.error(f"åˆ é™¤æŒä¹…åŒ–æ•°æ®å¤±è´¥: {e}")
                # ç»§ç»­æ‰§è¡Œï¼Œä¸è¦å› ä¸ºæ–‡ä»¶æ“ä½œå¤±è´¥è€Œä¸­æ–­
            
            # æ¸…ç†ç¼“å­˜
            try:
                await self.cache_service.invalidate_session_cache(session_id)
            except Exception as e:
                logger.warning(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
            
            logger.info(f"ä¼šè¯ {session_id} åˆ é™¤å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆ é™¤ä¼šè¯ {session_id} å¤±è´¥: {e}")
            raise RuntimeError(f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}")
    
    async def export_session(self, session_id: str, format: str = "json") -> Any:
        """å¯¼å‡ºä¼šè¯æ•°æ®"""
        requests = await self.get_all_session_requests(session_id)
        session_info = self.active_sessions.get(session_id, {})
        
        export_data = {
            "session_info": session_info,
            "requests": requests,
            "export_time": datetime.now().isoformat(),
            "format": format
        }
        
        if format == "json":
            return export_data
        elif format == "csv":
            return await self._export_to_csv(requests)
        elif format == "har":
            # ğŸŸ¢ ä½¿ç”¨ç°æœ‰HARå¯¼å‡ºåŠŸèƒ½ (å¦‚æœå·²å®ç°)
            return await self._export_to_har(requests)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")
    
    async def _save_session_data(self, session_id: str):
        """ä¿å­˜ä¼šè¯æ•°æ®åˆ°æŒä¹…åŒ–å­˜å‚¨"""
        recorder = self.session_recorders.get(session_id)
        
        if not recorder:
            return
        
        try:
            # ğŸŸ¢ è·å–ç°æœ‰NetworkRecorderçš„å½•åˆ¶ç»“æœ - ä½¿ç”¨recordså±æ€§
            recorded_requests = recorder.records
            
            # ğŸŸ¢ ä¿å­˜åˆ°sessionçº§åˆ«çš„requests.jsonæ–‡ä»¶
            # åºåˆ—åŒ–è¯·æ±‚è®°å½•ï¼ˆsession_idåœ¨sessionçº§åˆ«å­˜å‚¨ä¸­ä¸å†éœ€è¦ï¼‰
            serialized_requests = []
            for request in recorded_requests:
                try:
                    if isinstance(request, dict):
                        request_dict = request.copy()
                        serialized_requests.append(request_dict)
                    elif hasattr(request, 'to_dict'):
                        request_dict = request.to_dict()
                        serialized_requests.append(request_dict)
                    elif hasattr(request, '__dict__'):
                        # å¤„ç†å¯¹è±¡ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—å…¸
                        request_dict = {
                            key: value for key, value in request.__dict__.items()
                            if not key.startswith('_') and isinstance(value, (str, int, float, bool, list, dict, type(None)))
                        }
                        serialized_requests.append(request_dict)
                    else:
                        # è·³è¿‡æ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡
                        logger.warning(f"è·³è¿‡æ— æ³•åºåˆ—åŒ–çš„è¯·æ±‚å¯¹è±¡: {type(request)}")
                        continue
                except Exception as e:
                    logger.warning(f"åºåˆ—åŒ–è¯·æ±‚å¤±è´¥ï¼Œè·³è¿‡: {e}")
                    continue
            
            # è¦†ç›–ä¿å­˜åˆ° session çº§åˆ« requests.jsonï¼Œé¿å…é‡å¤è¿½åŠ å¯¼è‡´åŒä¸€ä¼šè¯æ•°æ®è†¨èƒ€
            # å¦‚éœ€å¢é‡ä¿å­˜ï¼Œåº”ç”±è°ƒç”¨æ–¹æ˜ç¡®å®ç°ï¼ˆç›®å‰ stop_recording ä¼šä¿å­˜æœ€ç»ˆç»“æœï¼‰
            HybridStorage.save_session_requests(session_id, serialized_requests)
            
            # ä¿å­˜ä¼šè¯å…ƒæ•°æ®
            sessions_file = HybridStorage.get_sessions_json_path()
            HybridStorage.ensure_sessions_json_exists()
            sessions = HybridStorage.load_json_data(sessions_file)
            
            # æ·»åŠ æˆ–æ›´æ–°å½“å‰ä¼šè¯
            session_data = self.active_sessions[session_id].copy()
            # ç¡®ä¿ä¼šè¯æ•°æ®å¯ä»¥åºåˆ—åŒ–
            for key, value in session_data.items():
                if not isinstance(value, (str, int, float, bool, list, dict, type(None))):
                    session_data[key] = str(value)
            
            if not isinstance(sessions, list):
                sessions = []
            sessions = [s for s in sessions if s.get("session_id") != session_id]
            sessions.append(session_data)
            
            HybridStorage.save_json_data(sessions_file, sessions)
            
            logger.info(f"ä¼šè¯æ•°æ®å·²ä¿å­˜åˆ°sessionçº§åˆ«å­˜å‚¨: {session_id}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ä¼šè¯æ•°æ®å¤±è´¥ {session_id}: {e}")
            raise
    
    async def _export_to_csv(self, requests: List[Dict]) -> str:
        """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
        import csv
        import io
        
        output = io.StringIO()
        
        if not requests:
            return ""
        
        # è·å–æ‰€æœ‰å­—æ®µå
        fieldnames = set()
        for req in requests:
            fieldnames.update(req.keys())
        
        writer = csv.DictWriter(output, fieldnames=list(fieldnames))
        writer.writeheader()
        writer.writerows(requests)
        
        return output.getvalue()
    
    async def _export_to_har(self, requests: List[Dict]) -> Dict:
        """å¯¼å‡ºä¸ºHARæ ¼å¼"""
        # ğŸŸ¢ ä½¿ç”¨ç°æœ‰har_exporteræ¨¡å— (å¦‚æœå­˜åœ¨)
        try:
            from core.har_exporter import HarExporter
            exporter = HarExporter()
            return await asyncio.get_event_loop().run_in_executor(
                None,
                exporter.export_to_har,
                requests
            )
        except ImportError:
            # å¦‚æœHARå¯¼å‡ºå™¨ä¸å­˜åœ¨ï¼Œè¿”å›åŸºæœ¬æ ¼å¼
            return {
                "log": {
                    "version": "1.2",
                    "creator": {"name": "Web Analyzer V2", "version": "2.0.0"},
                    "entries": requests
                }
            }
