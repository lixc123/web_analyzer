import asyncio
import json
import logging
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any
import hashlib

# å¯¼å…¥ç°æœ‰åˆ†æé€»è¾‘æ¨¡å— (é›¶ä¿®æ”¹å¤ç”¨)
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

import utils.analyzer as analyzer
from models.request_record import RequestRecord
import utils.file_helper as file_helper

from ..config import settings
from ..database import HybridStorage
from .cache_service import get_cache_service

logger = logging.getLogger(__name__)

class RequestAnalyzer:
    """è¯·æ±‚åˆ†æå™¨ - æä¾›å„ç§åˆ†æåŠŸèƒ½"""
    
    def __init__(self):
        pass
    
    def analyze_entropy(self, requests: List[RequestRecord], min_entropy: float = 4.0) -> Dict:
        """ç†µå€¼åˆ†æ"""
        high_entropy_requests: List[Dict] = []
        for r in requests:
            try:
                fields = analyzer.detect_high_entropy_fields(r)
            except Exception:
                fields = []

            if not fields:
                continue

            hits = []
            for f in fields:
                if getattr(f, "entropy", 0.0) >= min_entropy or getattr(f, "is_suspicious", False):
                    hits.append({
                        "name": getattr(f, "name", ""),
                        "location": getattr(f, "location", ""),
                        "entropy": getattr(f, "entropy", 0.0),
                        "length": getattr(f, "length", 0),
                        "value_preview": getattr(f, "value_preview", ""),
                        "charset": getattr(f, "charset", None),
                    })

            if hits:
                high_entropy_requests.append({
                    "id": r.id,
                    "url": r.url,
                    "method": r.method,
                    "risk_level": "medium",
                    "reason": f"æ£€æµ‹åˆ° {len(hits)} ä¸ªé«˜ç†µå­—æ®µ(>= {min_entropy})",
                    "high_entropy_fields": hits,
                })

        return {
            "high_entropy_requests": high_entropy_requests,
            "count": len(high_entropy_requests),
            "min_entropy": min_entropy,
        }
    
    def detect_sensitive_parameters(self, requests: List[RequestRecord], keywords: List[str] = None) -> Dict:
        """æ•æ„Ÿå‚æ•°åˆ†æ"""

        suspicious: List[Dict] = []
        try:
            sensitive_records = analyzer.find_sensitive_requests(requests)
        except Exception:
            sensitive_records = []

        for r in sensitive_records:
            suspicious.append({
                "id": r.id,
                "url": r.url,
                "method": r.method,
                "risk_level": "high",
                "reason": "URL/headers/body ä¸­å‡ºç°ç–‘ä¼¼æ•æ„Ÿå­—æ®µå…³é”®è¯",
            })

        return {
            "suspicious_requests": suspicious,
            "count": len(suspicious),
            "keywords": keywords or [],
        }
    
    def identify_encryption_keywords(self, requests: List[RequestRecord]) -> Dict:
        """åŠ å¯†å…³é”®è¯åˆ†æ"""

        suspicious: List[Dict] = []
        try:
            crypto_records = analyzer.find_crypto_suspected_requests(requests)
        except Exception:
            crypto_records = []

        for r in crypto_records:
            suspicious.append({
                "id": r.id,
                "url": r.url,
                "method": r.method,
                "risk_level": "low",
                "reason": "ç–‘ä¼¼åŒ…å«åŠ å¯†/ç­¾åç›¸å…³å…³é”®è¯æˆ–é«˜éšæœºæ€§å­—æ®µ",
            })

        return {
            "encrypted_requests": suspicious,
            "count": len(suspicious),
        }

    def analyze_sensitive_params(self, requests: List[RequestRecord], keywords: List[str] = None) -> Dict:
        return self.detect_sensitive_parameters(requests, keywords)

    def analyze_encryption_keywords(self, requests: List[RequestRecord]) -> Dict:
        return self.identify_encryption_keywords(requests)

class AnalysisService:
    """
    æ•°æ®åˆ†ææœåŠ¡ - å°è£…ç°æœ‰RequestAnalyzerç­‰åˆ†æé€»è¾‘
    ä¿æŒ100%ç®—æ³•ä¸€è‡´æ€§ï¼Œä»…æ·»åŠ FastAPIå…¼å®¹çš„å¼‚æ­¥æ¥å£
    """
    
    def __init__(self):
        self.cache_service = get_cache_service()
        # ğŸŸ¢ ç›´æ¥ä½¿ç”¨ç°æœ‰RequestAnalyzerç±» (é›¶ä¿®æ”¹)
        self.analyzer = RequestAnalyzer()
        
        # åˆ†æç»“æœå­˜å‚¨
        self.analysis_results: Dict[str, Dict] = {}
        
        # è‡ªå®šä¹‰è§„åˆ™å­˜å‚¨
        self.custom_rules: Dict[str, Dict] = {}
    
    async def analyze(self, session_id: Optional[str] = None, 
                     requests_data: Optional[List[Dict]] = None, 
                     config: Dict = None) -> Dict:
        """
        æ‰§è¡Œç»¼åˆåˆ†æ
        æ”¯æŒä¼ å…¥session_idæˆ–ç›´æ¥ä¼ å…¥è¯·æ±‚æ•°æ®
        """
        analysis_id = str(uuid.uuid4())
        analysis_type = config.get("analysis_type", "all")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key_data = {
            "session_id": session_id,
            "requests_hash": self._hash_requests(requests_data) if requests_data else None,
            "config": config
        }
        
        cached_result = await self.cache_service.get_analysis_result(
            session_id or "direct", analysis_type, cache_key_data
        )
        
        if cached_result:
            logger.info(f"ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ: {analysis_id}")
            return cached_result
        
        try:
            # è·å–è¦åˆ†æçš„è¯·æ±‚æ•°æ®
            if requests_data:
                requests = requests_data
            elif session_id:
                requests = await self._load_session_requests(session_id)
            else:
                raise ValueError("å¿…é¡»æä¾› session_id æˆ– requests_data")
            
            if not requests:
                raise ValueError("æ²¡æœ‰å¯åˆ†æçš„è¯·æ±‚æ•°æ®")
            
            # ğŸŸ¢ å°†è¯·æ±‚æ•°æ®è½¬æ¢ä¸ºRequestRecordå¯¹è±¡ (ä½¿ç”¨ç°æœ‰æ¨¡å‹)
            request_records = []
            for req_data in requests:
                if isinstance(req_data, dict):
                    # ä»å­—å…¸åˆ›å»ºRequestRecordå¯¹è±¡
                    record = RequestRecord.from_dict(req_data)
                    request_records.append(record)
                elif isinstance(req_data, RequestRecord):
                    request_records.append(req_data)
            
            # æ‰§è¡Œä¸åŒç±»å‹çš„åˆ†æ
            results = {}
            suspicious_requests = []
            
            if analysis_type in ["all", "entropy"]:
                # ğŸŸ¢ ä½¿ç”¨ç°æœ‰ç†µå€¼åˆ†æç®—æ³• (é›¶ä¿®æ”¹)
                entropy_results = await asyncio.get_event_loop().run_in_executor(
                    None,
                    self.analyzer.analyze_entropy,
                    request_records,
                    config.get("min_entropy", 4.0)
                )
                results["entropy"] = entropy_results
                suspicious_requests.extend(entropy_results.get("high_entropy_requests", []))
            
            if analysis_type in ["all", "sensitive_params"]:
                # ğŸŸ¢ ä½¿ç”¨ç°æœ‰æ•æ„Ÿå‚æ•°æ£€æµ‹ (é›¶ä¿®æ”¹)
                sensitive_results = await asyncio.get_event_loop().run_in_executor(
                    None,
                    self.analyzer.detect_sensitive_parameters,
                    request_records,
                    config.get("sensitive_keywords", [])
                )
                results["sensitive_params"] = sensitive_results
                suspicious_requests.extend(sensitive_results.get("suspicious_requests", []))
            
            if analysis_type in ["all", "encryption_keywords"]:
                # ğŸŸ¢ ä½¿ç”¨ç°æœ‰åŠ å¯†å…³é”®è¯è¯†åˆ« (é›¶ä¿®æ”¹)
                encryption_results = await asyncio.get_event_loop().run_in_executor(
                    None,
                    self.analyzer.identify_encryption_keywords,
                    request_records
                )
                results["encryption_keywords"] = encryption_results
                suspicious_requests.extend(encryption_results.get("encrypted_requests", []))
            
            # åº”ç”¨è‡ªå®šä¹‰è§„åˆ™
            if config.get("custom_rules"):
                custom_results = await self._apply_custom_rules(
                    request_records, config["custom_rules"]
                )
                results["custom"] = custom_results
                suspicious_requests.extend(custom_results.get("matches", []))
            
            # ç”Ÿæˆåˆ†ææ‘˜è¦
            summary = await self._generate_analysis_summary(results, request_records)
            
            # å»é‡å¯ç–‘è¯·æ±‚
            unique_suspicious = self._deduplicate_suspicious_requests(suspicious_requests)
            
            analysis_result = {
                "analysis_id": analysis_id,
                "session_id": session_id,
                "analysis_type": analysis_type,
                "results": results,
                "summary": summary,
                "suspicious_requests": unique_suspicious,
                "timestamp": datetime.now().isoformat(),
                "config": config,
                "total_requests_analyzed": len(request_records)
            }
            
            # å­˜å‚¨åˆ†æç»“æœ
            self.analysis_results[analysis_id] = analysis_result
            
            # ç¼“å­˜ç»“æœ
            await self.cache_service.set_analysis_result(
                session_id or "direct", analysis_type, cache_key_data, analysis_result
            )
            
            logger.info(f"åˆ†æå®Œæˆ: {analysis_id}, åˆ†æäº† {len(request_records)} ä¸ªè¯·æ±‚")
            return analysis_result
            
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            raise
    
    async def analyze_entropy(self, session_id: str, min_entropy: float = 4.0) -> List[Dict]:
        """å•ç‹¬æ‰§è¡Œç†µå€¼åˆ†æ"""
        requests = await self._load_session_requests(session_id)
        request_records = [RequestRecord.from_dict(req) for req in requests]
        
        # ğŸŸ¢ ä½¿ç”¨ç°æœ‰ç†µå€¼åˆ†æç®—æ³• (é›¶ä¿®æ”¹)
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            self.analyzer.analyze_entropy,
            request_records,
            min_entropy
        )
        
        return result.get("high_entropy_requests", [])
    
    async def analyze_sensitive_params(self, session_id: str, custom_keywords: List[str] = None) -> List[Dict]:
        """å•ç‹¬æ‰§è¡Œæ•æ„Ÿå‚æ•°åˆ†æ"""
        requests = await self._load_session_requests(session_id)
        request_records = [RequestRecord.from_dict(req) for req in requests]
        
        # ğŸŸ¢ ä½¿ç”¨ç°æœ‰æ•æ„Ÿå‚æ•°æ£€æµ‹ (é›¶ä¿®æ”¹)
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            self.analyzer.detect_sensitive_parameters,
            request_records,
            custom_keywords or []
        )
        
        return result.get("suspicious_requests", [])
    
    async def analyze_encryption_keywords(self, session_id: str) -> List[Dict]:
        """å•ç‹¬æ‰§è¡ŒåŠ å¯†å…³é”®è¯åˆ†æ"""
        requests = await self._load_session_requests(session_id)
        request_records = [RequestRecord.from_dict(req) for req in requests]
        
        # ğŸŸ¢ ä½¿ç”¨ç°æœ‰åŠ å¯†å…³é”®è¯è¯†åˆ« (é›¶ä¿®æ”¹)
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            self.analyzer.identify_encryption_keywords,
            request_records
        )
        
        return result.get("encrypted_requests", [])
    
    async def get_analysis_summary(self, session_id: str) -> Dict:
        """è·å–ä¼šè¯çš„åˆ†ææ‘˜è¦"""
        # æŸ¥æ‰¾è¯¥ä¼šè¯çš„æ‰€æœ‰åˆ†æç»“æœ
        session_analyses = [
            result for result in self.analysis_results.values()
            if result.get("session_id") == session_id
        ]
        
        if not session_analyses:
            # å¦‚æœæ²¡æœ‰ç°æœ‰åˆ†æï¼Œæ‰§è¡Œä¸€æ¬¡å¿«é€Ÿåˆ†æ
            analysis = await self.analyze(session_id=session_id, config={"analysis_type": "all"})
            return analysis["summary"]
        
        # åˆå¹¶å¤šæ¬¡åˆ†æçš„æ‘˜è¦
        combined_summary = {
            "total_analyses": len(session_analyses),
            "latest_analysis": session_analyses[-1]["timestamp"],
            "total_suspicious_requests": 0,
            "risk_levels": {"high": 0, "medium": 0, "low": 0},
            "analysis_types": []
        }
        
        for analysis in session_analyses:
            summary = analysis.get("summary", {})
            combined_summary["total_suspicious_requests"] += len(analysis.get("suspicious_requests", []))
            combined_summary["analysis_types"].append(analysis["analysis_type"])
            
            # åˆå¹¶é£é™©çº§åˆ«ç»Ÿè®¡
            for level in ["high", "medium", "low"]:
                combined_summary["risk_levels"][level] += summary.get("risk_levels", {}).get(level, 0)
        
        return combined_summary
    
    async def create_custom_rule(self, rule_name: str, rule_config: Dict) -> str:
        """åˆ›å»ºè‡ªå®šä¹‰åˆ†æè§„åˆ™"""
        rule_id = str(uuid.uuid4())
        
        rule_data = {
            "rule_id": rule_id,
            "rule_name": rule_name,
            "config": rule_config,
            "created_at": datetime.now().isoformat(),
            "enabled": True
        }
        
        self.custom_rules[rule_id] = rule_data
        
        # æŒä¹…åŒ–è‡ªå®šä¹‰è§„åˆ™
        await self._save_custom_rules()
        
        logger.info(f"åˆ›å»ºè‡ªå®šä¹‰è§„åˆ™: {rule_name} ({rule_id})")
        return rule_id
    
    async def list_rules(self) -> Dict:
        """åˆ—å‡ºæ‰€æœ‰åˆ†æè§„åˆ™"""
        # å†…ç½®è§„åˆ™
        builtin_rules = {
            "entropy": {
                "name": "é«˜ç†µå­—æ®µæ£€æµ‹",
                "description": "æ£€æµ‹é«˜ç†µå€¼å­—æ®µï¼Œå¯èƒ½åŒ…å«åŠ å¯†æ•°æ®",
                "type": "builtin"
            },
            "sensitive_params": {
                "name": "æ•æ„Ÿå‚æ•°æ£€æµ‹", 
                "description": "æ£€æµ‹å¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯çš„å‚æ•°",
                "type": "builtin"
            },
            "encryption_keywords": {
                "name": "åŠ å¯†å…³é”®è¯è¯†åˆ«",
                "description": "è¯†åˆ«åŠ å¯†ç›¸å…³çš„å…³é”®è¯å’Œæ¨¡å¼",
                "type": "builtin"
            }
        }
        
        return {
            "builtin_rules": builtin_rules,
            "custom_rules": self.custom_rules
        }
    
    async def get_analysis_history(self, session_id: str, limit: int = 20, offset: int = 0) -> List[Dict]:
        """è·å–åˆ†æå†å²è®°å½•"""
        session_analyses = [
            {
                "analysis_id": aid,
                "analysis_type": result["analysis_type"],
                "timestamp": result["timestamp"],
                "suspicious_count": len(result.get("suspicious_requests", [])),
                "summary": result.get("summary", {})
            }
            for aid, result in self.analysis_results.items()
            if result.get("session_id") == session_id
        ]
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        session_analyses.sort(key=lambda x: x["timestamp"], reverse=True)
        
        return session_analyses[offset:offset + limit]
    
    async def compare_results(self, analysis_ids: List[str]) -> Dict:
        """æ¯”è¾ƒå¤šä¸ªåˆ†æç»“æœ"""
        if len(analysis_ids) < 2:
            raise ValueError("è‡³å°‘éœ€è¦2ä¸ªåˆ†æç»“æœè¿›è¡Œæ¯”è¾ƒ")
        
        analyses = []
        for aid in analysis_ids:
            if aid not in self.analysis_results:
                raise ValueError(f"åˆ†æç»“æœ {aid} ä¸å­˜åœ¨")
            analyses.append(self.analysis_results[aid])
        
        comparison = {
            "analysis_ids": analysis_ids,
            "comparison_time": datetime.now().isoformat(),
            "metrics": {
                "suspicious_requests": [len(a.get("suspicious_requests", [])) for a in analyses],
                "analysis_types": [a["analysis_type"] for a in analyses],
                "request_counts": [a.get("total_requests_analyzed", 0) for a in analyses]
            },
            "differences": [],
            "common_patterns": []
        }
        
        # åˆ†æå·®å¼‚å’Œå…±åŒæ¨¡å¼
        all_suspicious = []
        for analysis in analyses:
            all_suspicious.extend(analysis.get("suspicious_requests", []))
        
        # ç»Ÿè®¡å…±åŒå‡ºç°çš„å¯ç–‘è¯·æ±‚
        url_counts = {}
        for req in all_suspicious:
            url = req.get("url", "")
            url_counts[url] = url_counts.get(url, 0) + 1
        
        common_patterns = [
            {"url": url, "occurrences": count}
            for url, count in url_counts.items()
            if count > 1
        ]
        
        comparison["common_patterns"] = common_patterns
        return comparison
    
    async def export_analysis(self, analysis_id: str, format: str = "json") -> Any:
        """å¯¼å‡ºåˆ†æç»“æœ"""
        if analysis_id not in self.analysis_results:
            raise ValueError(f"åˆ†æç»“æœ {analysis_id} ä¸å­˜åœ¨")
        
        result = self.analysis_results[analysis_id]
        
        if format == "json":
            return result
        elif format == "csv":
            return await self._export_analysis_to_csv(result)
        elif format == "pdf":
            return await self._export_analysis_to_pdf(result)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")
    
    async def _load_session_requests(self, session_id: str) -> List[Dict]:
        """ä»å­˜å‚¨ä¸­åŠ è½½ä¼šè¯è¯·æ±‚æ•°æ®"""
        try:
            # ğŸŸ¢ ä¼˜å…ˆä»sessionçº§åˆ«å­˜å‚¨åŠ è½½
            session_requests = HybridStorage.load_session_requests(session_id)
            
            if session_requests:
                logger.info(f"ä»sessionçº§åˆ«å­˜å‚¨åŠ è½½äº† {len(session_requests)} ä¸ªè¯·æ±‚")
                return session_requests
            
            # ğŸŸ¢ å‘åå…¼å®¹ï¼šå¦‚æœsessionçº§åˆ«æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»å…¨å±€requests.jsonåŠ è½½
            requests_file = HybridStorage.get_requests_json_path()
            if not os.path.exists(requests_file):
                logger.warning(f"ä¼šè¯ {session_id} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¯·æ±‚æ•°æ®")
                return []
            
            with open(requests_file, 'r', encoding='utf-8') as f:
                all_requests = json.load(f)
            
            # è¿‡æ»¤æŒ‡å®šä¼šè¯çš„è¯·æ±‚
            session_requests = [
                req for req in all_requests 
                if req.get("session_id") == session_id
            ]
            
            logger.info(f"ä»å…¨å±€å­˜å‚¨åŠ è½½äº† {len(session_requests)} ä¸ªä¼šè¯è¯·æ±‚")
            return session_requests
            
        except Exception as e:
            logger.error(f"åŠ è½½ä¼šè¯è¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def _hash_requests(self, requests_data: List[Dict]) -> str:
        """è®¡ç®—è¯·æ±‚æ•°æ®çš„å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
        if not requests_data:
            return ""
        
        # åˆ›å»ºè¯·æ±‚æ•°æ®çš„ç®€åŒ–ç‰ˆæœ¬ç”¨äºå“ˆå¸Œ
        simplified = []
        for req in requests_data[:100]:  # åªå–å‰100ä¸ªè¯·æ±‚è®¡ç®—å“ˆå¸Œ
            simplified.append({
                "url": req.get("url", ""),
                "method": req.get("method", ""),
                "status": req.get("status") if req.get("status") is not None else req.get("status_code", 0)
            })
        
        data_str = json.dumps(simplified, sort_keys=True)
        return hashlib.md5(data_str.encode()).hexdigest()
    
    async def _apply_custom_rules(self, request_records: List[RequestRecord], rules: Dict) -> Dict:
        """åº”ç”¨è‡ªå®šä¹‰åˆ†æè§„åˆ™"""
        matches = []
        
        for rule_id, rule_config in rules.items():
            if rule_id in self.custom_rules:
                rule = self.custom_rules[rule_id]
                if not rule.get("enabled", True):
                    continue
                
                # åº”ç”¨è§„åˆ™é€»è¾‘
                rule_matches = await self._execute_custom_rule(request_records, rule["config"])
                matches.extend(rule_matches)
        
        return {"matches": matches, "rules_applied": len(rules)}
    
    async def _execute_custom_rule(self, request_records: List[RequestRecord], rule_config: Dict) -> List[Dict]:
        """æ‰§è¡Œå•ä¸ªè‡ªå®šä¹‰è§„åˆ™"""
        matches = []
        
        # è¿™é‡Œå¯ä»¥å®ç°å¤æ‚çš„è‡ªå®šä¹‰è§„åˆ™é€»è¾‘
        # ç›®å‰å®ç°ä¸€ä¸ªç®€å•çš„å…³é”®è¯åŒ¹é…è§„åˆ™
        keywords = rule_config.get("keywords", [])
        fields = rule_config.get("fields", ["url", "request_body", "response_body"])
        
        for record in request_records:
            record_dict = record.to_dict() if hasattr(record, 'to_dict') else record
            
            for field in fields:
                field_value = str(record_dict.get(field, "")).lower()
                
                for keyword in keywords:
                    if keyword.lower() in field_value:
                        matches.append({
                            "url": record_dict.get("url", ""),
                            "method": record_dict.get("method", ""),
                            "matched_field": field,
                            "matched_keyword": keyword,
                            "rule_type": "custom"
                        })
                        break
        
        return matches
    
    async def _generate_analysis_summary(self, results: Dict, request_records: List) -> Dict:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        summary = {
            "total_requests": len(request_records),
            "analysis_types": list(results.keys()),
            "suspicious_count": 0,
            "risk_levels": {"high": 0, "medium": 0, "low": 0},
            "top_issues": [],
            "recommendations": []
        }
        
        # ç»Ÿè®¡å¯ç–‘è¯·æ±‚æ•°é‡å’Œé£é™©çº§åˆ«
        for analysis_type, result in results.items():
            if analysis_type == "entropy":
                high_entropy = result.get("high_entropy_requests", [])
                summary["suspicious_count"] += len(high_entropy)
                summary["risk_levels"]["medium"] += len(high_entropy)
                
            elif analysis_type == "sensitive_params":
                sensitive = result.get("suspicious_requests", [])
                summary["suspicious_count"] += len(sensitive)
                summary["risk_levels"]["high"] += len(sensitive)
                
            elif analysis_type == "encryption_keywords":
                encrypted = result.get("encrypted_requests", [])
                summary["suspicious_count"] += len(encrypted)
                summary["risk_levels"]["low"] += len(encrypted)
        
        # ç”Ÿæˆå»ºè®®
        if summary["risk_levels"]["high"] > 0:
            summary["recommendations"].append("å‘ç°é«˜é£é™©æ•æ„Ÿå‚æ•°ï¼Œå»ºè®®ç«‹å³æ£€æŸ¥ç›¸å…³è¯·æ±‚")
        
        if summary["risk_levels"]["medium"] > 5:
            summary["recommendations"].append("å‘ç°å¤šä¸ªé«˜ç†µå­—æ®µï¼Œå¯èƒ½åŒ…å«åŠ å¯†æ•°æ®")
        
        return summary
    
    def _deduplicate_suspicious_requests(self, suspicious_requests: List[Dict]) -> List[Dict]:
        """å»é‡å¯ç–‘è¯·æ±‚"""
        seen = set()
        unique_requests = []
        
        for req in suspicious_requests:
            # ä½¿ç”¨URL+æ–¹æ³•ä½œä¸ºå»é‡é”®
            key = f"{req.get('url', '')}:{req.get('method', '')}"
            if key not in seen:
                seen.add(key)
                unique_requests.append(req)
        
        return unique_requests
    
    async def _save_custom_rules(self):
        """ä¿å­˜è‡ªå®šä¹‰è§„åˆ™åˆ°æ–‡ä»¶"""
        rules_file = os.path.join(settings.data_dir, "custom_rules.json")
        
        try:
            with open(rules_file, 'w', encoding='utf-8') as f:
                json.dump(self.custom_rules, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜è‡ªå®šä¹‰è§„åˆ™å¤±è´¥: {e}")
    
    async def _export_analysis_to_csv(self, result: Dict) -> str:
        """å¯¼å‡ºåˆ†æç»“æœä¸ºCSV"""
        import csv
        import io
        
        output = io.StringIO()
        
        # å¯¼å‡ºå¯ç–‘è¯·æ±‚åˆ—è¡¨
        suspicious = result.get("suspicious_requests", [])
        if suspicious:
            fieldnames = set()
            for req in suspicious:
                fieldnames.update(req.keys())
            
            writer = csv.DictWriter(output, fieldnames=list(fieldnames))
            writer.writeheader()
            writer.writerows(suspicious)
        
        return output.getvalue()
    
    async def _export_analysis_to_pdf(self, result: Dict) -> bytes:
        """å¯¼å‡ºåˆ†æç»“æœä¸ºPDF"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨reportlabç­‰åº“ç”ŸæˆPDFæŠ¥å‘Š
        # ç›®å‰è¿”å›ç®€å•çš„æ–‡æœ¬æ ¼å¼
        
        report = f"""
åˆ†ææŠ¥å‘Š
========

åˆ†æID: {result['analysis_id']}
åˆ†ææ—¶é—´: {result['timestamp']}
åˆ†æç±»å‹: {result['analysis_type']}

æ‘˜è¦:
- æ€»è¯·æ±‚æ•°: {result['summary']['total_requests']}
- å¯ç–‘è¯·æ±‚æ•°: {result['summary']['suspicious_count']}
- é«˜é£é™©: {result['summary']['risk_levels']['high']}
- ä¸­é£é™©: {result['summary']['risk_levels']['medium']}
- ä½é£é™©: {result['summary']['risk_levels']['low']}

å»ºè®®:
""" + "\n".join(f"- {rec}" for rec in result['summary']['recommendations'])
        
        return report.encode('utf-8')
